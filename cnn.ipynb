{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used libraries for the entire project\n",
    "\"\"\"\n",
    "import torch\n",
    "import os\n",
    "import optuna\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset, random_split, ConcatDataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishesd\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Normalize pixel values and create training and testing datasets --\n",
    "\n",
    "This cell normalizes the pixel values and creates a training\n",
    "and testing datasets considering the stratify technique.\n",
    "\"\"\"\n",
    "\n",
    "parent_folder_path = 'images/cropped_dataset/'\n",
    "categories = {'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral_Pneumonia': 3}\n",
    "arrays = []\n",
    "category_amount = []\n",
    "\n",
    "# get the category with the least images\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(parent_folder_path, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    category_amount.append(len(image_files))\n",
    "\n",
    "max_training = min(category_amount)\n",
    "\n",
    "# convert the images into a pytorch dataset\n",
    "for cat_folder, value in categories.items():\n",
    "\n",
    "    folder_path = os.path.join(parent_folder_path, cat_folder)\n",
    "    image_files = os.listdir(folder_path)\n",
    "\n",
    "    for i, file_name in enumerate(image_files):\n",
    "\n",
    "        if i >= max_training: break\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        image = Image.open(file_path)\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # verify all images are of the desired size\n",
    "        if image.size != (250, 250):\n",
    "            print(file_path, \" IS NOT 250x250, it is: \", image.size)\n",
    "            continue\n",
    "\n",
    "        if image_array.shape != (250, 250):\n",
    "            image_array = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "        arrays.append(image_array)\n",
    "\n",
    "# reshape the array\n",
    "arrays = arrays/ np.max(arrays)\n",
    "#image_data = np.stack(arrays, axis=0)\n",
    "#image_data = image_data.reshape(len(image_data), 1, 250, 250)\n",
    "\n",
    "arrays_labels = [0] * max_training\n",
    "arrays_labels += [1] * max_training\n",
    "arrays_labels += [2] * max_training\n",
    "arrays_labels += [3] * max_training\n",
    "\n",
    "arrays_labels = np.array(arrays_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arrays, arrays_labels, test_size=0.2, random_state=42, stratify=arrays_labels)\n",
    "\n",
    "print(\"Finishesd\")\n",
    "\n",
    "y_train = to_categorical(y_train.astype(int), num_classes=4)\n",
    "y_test = to_categorical(y_test.astype(int), num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72/72 [==============================] - 79s 1s/step - loss: 3.3637 - accuracy: 0.4550\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 72s 994ms/step - loss: 0.8578 - accuracy: 0.6374\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 69s 962ms/step - loss: 0.7452 - accuracy: 0.7001\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 69s 959ms/step - loss: 0.7081 - accuracy: 0.7158\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 69s 965ms/step - loss: 0.6270 - accuracy: 0.7567\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 70s 975ms/step - loss: 0.5878 - accuracy: 0.7676\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 71s 988ms/step - loss: 0.5648 - accuracy: 0.7779\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.5338 - accuracy: 0.7930\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.4959 - accuracy: 0.8086\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 72s 997ms/step - loss: 0.4512 - accuracy: 0.8325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e145e4410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo de red convolucional\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(250, 250, 1)))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Trian the model\n",
    "model_cnn.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 6s 78ms/step\n",
      "[[1.0206821e-01 8.4898204e-01 4.6368141e-02 2.5816644e-03]\n",
      " [2.0091405e-02 4.5901218e-01 4.2823654e-01 9.2659913e-02]\n",
      " [3.4709400e-03 7.7527940e-02 9.1899747e-01 3.5843686e-06]\n",
      " ...\n",
      " [2.2760148e-03 1.2052284e-02 9.6682256e-01 1.8849058e-02]\n",
      " [3.4139088e-01 2.0502605e-02 7.6577114e-03 6.3044888e-01]\n",
      " [6.2732227e-02 7.7702396e-02 8.5953486e-01 3.0483776e-05]]\n"
     ]
    }
   ],
   "source": [
    "pred = model_cnn.predict(X_test)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
