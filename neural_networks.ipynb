{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 - Redes Neuronales\n",
    "Curso: Introducción al Reconocimiento de Patrones\n",
    "\n",
    "Estudiantes:\n",
    "- Juan Ignacio Navarro Navarro\n",
    "- Jose David Sánchez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used libraries for the entire project\n",
    "\"\"\"\n",
    "import torch\n",
    "import os\n",
    "import optuna\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset, random_split, ConcatDataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del Set de Datos de Rayos X en Pulmones\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los sets de datos utilizados son:\n",
    "- https://www.kaggle.com/datasets/preetviradiya/covid19-radiography-dataset (original propuesto por el profesor, guardado en images/original_dataset)\n",
    "- https://www.kaggle.com/datasets/gibi13/pneumonia-covid19-image-dataset (adicional para disminuir sesgo, guardado en images/additional_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Load images from additional dataset to decrease bias --\n",
    "\n",
    "Description: This cell moves the images needed to decrease the\n",
    "models bias from the additional dataset to the analysis dataset.\n",
    "The analysis dataset contains the needed images from both original\n",
    "and additional dataset.\n",
    "\n",
    "Since the images from both dataset had different sizes this cell\n",
    "also defines a standard size.\n",
    "\"\"\"\n",
    "\n",
    "# Define the input folder with the original images\n",
    "input_folder = \"images/additional_dataset/\"\n",
    "\n",
    "# Define the output folder to save the resized\n",
    "output_folder = \"images/analysis_dataset/\"\n",
    "\n",
    "# Define the target size for the resized images\n",
    "target_size = (299, 299)\n",
    "\n",
    "categories = ['COVID', 'Viral_Pneumonia']\n",
    "\n",
    "for category in categories:\n",
    "    # Get the list of files in the input folder\n",
    "    file_list = os.listdir(os.path.join(input_folder, category))\n",
    "\n",
    "    # Iterate over each file in the input folder\n",
    "    for file_name in file_list:\n",
    "        input_path = os.path.join(input_folder, category, file_name)\n",
    "        \n",
    "        image = Image.open(input_path)\n",
    "        resized_image = image.resize(target_size)\n",
    "        output_path = os.path.join(output_folder, category, file_name)\n",
    "        \n",
    "        # Save the resized image to the output folder\n",
    "        resized_image.save(output_path)\n",
    "        image.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Delete images from cropped dataset --\n",
    "\n",
    "This cell deletes the files in the cropped dataset if any. The\n",
    "cropped dataset a cropped copy from the additional dataset images.\n",
    "The images are cropped to show only the most important part of \n",
    "the X-rays, which is the lungs\n",
    "\"\"\"\n",
    "\n",
    "cropped_images_folder = 'images/cropped_dataset/'\n",
    "categories = {'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral_Pneumonia': 3}\n",
    "\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(cropped_images_folder, category)\n",
    "\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(cropped_images_folder, category, file_name)\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of images in analysis dataset:\n",
      "\tCOVID\t\t\t : 4596\n",
      "         Lung_Opacity\t\t : 6012\n",
      "         Normal\t\t\t : 10192\n",
      "         Viral_Pneumonia\t : 2857\n",
      "\n",
      "Maximum amount of images to use in the training:  2857\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Crop images borders and ignore extra images on bias --\n",
    "\n",
    "This cell crops the images borders on analysis dataset an saves\n",
    "them into the cropped dataset folder. It only saves the images \n",
    "needed to train the model without bias.\n",
    "\"\"\"\n",
    "\n",
    "# define a different folder to save the cropped images\n",
    "original_images_folder = 'images/analysis_dataset/'\n",
    "cropped_images_folder = 'images/cropped_dataset/'\n",
    "\n",
    "# define the new size\n",
    "target_size = (250, 250)\n",
    "\n",
    "categories = {'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral_Pneumonia': 3}\n",
    "category_amount = []\n",
    "\n",
    "# get the amount of images for each category\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(original_images_folder, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    category_amount.append(len(image_files))\n",
    "\n",
    "print(\"Amount of images in analysis dataset:\")\n",
    "print(f\"\\tCOVID\\t\\t\\t : {category_amount[0]}\\n \\\n",
    "        Lung_Opacity\\t\\t : {category_amount[1]}\\n \\\n",
    "        Normal\\t\\t\\t : {category_amount[2]}\\n \\\n",
    "        Viral_Pneumonia\\t : {category_amount[3]}\\n\")\n",
    "\n",
    "max_training = min(category_amount)\n",
    "print(\"Maximum amount of images to use in the training: \", min(category_amount))\n",
    "\n",
    "# crop and save the cropped images\n",
    "for category in categories.keys():\n",
    "\n",
    "    cat_files = os.listdir(os.path.join(original_images_folder, category))\n",
    "\n",
    "    for i, file in enumerate(cat_files):\n",
    "\n",
    "        if i == max_training: break\n",
    "        # constructing image path\n",
    "        input_path = os.path.join(original_images_folder, category, file)\n",
    "        image = Image.open(input_path)\n",
    "\n",
    "        if image.size[0] < 299 or image.size[1] < 299:\n",
    "            continue\n",
    "        \n",
    "        # get original image size and calculate borders\n",
    "        width, height = image.size\n",
    "        left = (width - target_size[0]) // 2\n",
    "        upper = (height - target_size[1]) // 2\n",
    "        right = left + target_size[0]\n",
    "        lower = upper + target_size[1]\n",
    "\n",
    "        # crop the image\n",
    "        cropped_image = image.crop((left, upper, right, lower))\n",
    "        output_path = os.path.join(cropped_images_folder, category, file)\n",
    "        cropped_image.save(output_path)\n",
    "        image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Normalize pixel values and create training and testing datasets --\n",
    "\n",
    "This cell normalizes the pixel values and creates a training\n",
    "and testing datasets considering the stratify technique.\n",
    "\"\"\"\n",
    "\n",
    "parent_folder_path = 'images/cropped_dataset/'\n",
    "categories = {'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral_Pneumonia': 3}\n",
    "arrays = []\n",
    "category_amount = []\n",
    "\n",
    "# get the category with the least images\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(parent_folder_path, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    category_amount.append(len(image_files))\n",
    "\n",
    "max_training = min(category_amount)\n",
    "\n",
    "# convert the images into a pytorch dataset\n",
    "for cat_folder, value in categories.items():\n",
    "\n",
    "    folder_path = os.path.join(parent_folder_path, cat_folder)\n",
    "    image_files = os.listdir(folder_path)\n",
    "\n",
    "    for i, file_name in enumerate(image_files):\n",
    "\n",
    "        if i >= max_training: break\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        image = Image.open(file_path)\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # verify all images are of the desired size\n",
    "        if image.size != (250, 250):\n",
    "            print(file_path, \" IS NOT 250x250, it is: \", image.size)\n",
    "            continue\n",
    "\n",
    "        if image_array.shape != (250, 250):\n",
    "            image_array = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "        arrays.append(image_array)\n",
    "\n",
    "# reshape the array\n",
    "arrays = arrays/ np.max(arrays)\n",
    "image_data = np.stack(arrays, axis=0)\n",
    "image_data = image_data.reshape(len(image_data), 1, 250, 250)\n",
    "image_data = torch.from_numpy(image_data).to(torch.float32)\n",
    "\n",
    "# Stratify - get a random amount of values from\n",
    "train_perc = 0.8\n",
    "\n",
    "train_size = int(train_perc * max_training)\n",
    "test_size = max_training - train_size\n",
    "\n",
    "# Get the training and testing dataset\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "for category, value in categories.items():\n",
    "    train_cat_dataset, test_cat_dataset = random_split(image_data[value*max_training:(value+1)*max_training], [train_size, test_size])\n",
    "    train_dataset.append(train_cat_dataset)\n",
    "    test_dataset.append(test_cat_dataset)\n",
    "    train_cat_labels = [value] * train_size\n",
    "    train_labels += train_cat_labels\n",
    "    test_cat_labels = [value] * test_size\n",
    "    test_labels += test_cat_labels\n",
    "\n",
    "# Convert the lists into the types needed to train the models\n",
    "train_dataset = ConcatDataset(train_dataset)\n",
    "test_dataset = ConcatDataset(test_dataset)\n",
    "train_labels = torch.from_numpy(np.array(train_labels)).to(torch.long)\n",
    "test_labels = torch.from_numpy(np.array(test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro - Bilateral filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con Perceptrón multicapa (MLP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se realiza lo siguiente:\n",
    "- se define el modelo de MLP\n",
    "- se entrena el modelo sin feature extractor\n",
    "- se prueba el modelo sin feature extractor\n",
    "- se entrena el modelo con feature extractor\n",
    "- se prueba el modelo con feature extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con Red Convolucional "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se realiza lo siguiente:\n",
    "- se define el modelo de CNN\n",
    "- se entrena el modelo con las imágenes sin filtro\n",
    "- se prueba el modelo con las imágenes sin filtro\n",
    "- se entrena el modelo con las imágenes con filtro\n",
    "- se prueba el modelo con las imágenes con filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Define the CNN module --\n",
    "\n",
    "This cell defines a CNN module class of a network that has 2 internal\n",
    "convolutional layers. Also some training and testing functions were\n",
    "implemented.\n",
    "\"\"\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, device, image_sizes= 299, kernel_size=3, max_pool_size=2, lr=0.001, epochs=3):\n",
    "        \"\"\"\n",
    "        CNN contructor\n",
    "        inputs:\n",
    "        device - device in which the cnn will be executed\n",
    "        kernel_size (hiperparameter) - this is the size that will be used in the convolution layers\n",
    "            type: int, a single number will work with a grid of size n x n\n",
    "        max_pool_size - this is the size of the pooling layer\n",
    "        lr (hiperparameter) - the learning rate that will be used to train the cnn\n",
    "        epochs (hiperparmeter) - the amount of iterations that will be used to train the cnn\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=max_pool_size, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=max_pool_size, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * (image_sizes//(max_pool_size**2))**2, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward function is used in the training to understand the infrastructure\n",
    "        of the proposed model\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train_cnn(self, train_dataset, train_labels):\n",
    "        \"\"\"\n",
    "        Method to train the cnn based on the inputs:\n",
    "        train_dataset - tensor with the information of the pixels of the images\n",
    "        train_labels - tesnro with the category of each of the images frrom the train_dataset\n",
    "        \"\"\"\n",
    "        # Set the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), self.lr)\n",
    "\n",
    "        # Create a data loader for the training dataset\n",
    "        train_loader = DataLoader(dataset=list(zip(train_dataset, train_labels)), batch_size=16, shuffle=True)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "            for images, labels in train_loader:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(train_dataset)\n",
    "            #print(\"Running loss: \", running_loss)\n",
    "            #print(f\"Epoch [{epoch+1}/{self.epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        print(f\"Finished training with lr={self.lr} and epochs={self.epochs}\")\n",
    "\n",
    "    def predict(self, test_dataset):\n",
    "        \"\"\"\n",
    "        Method used to predict the outputs of the test_dataset\n",
    "        with the model.\n",
    "        Input: test_dataset -> tensor with inputs of every test image\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        self.eval() \n",
    "        # Create a data loader for the training dataset\n",
    "        dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for inputs in dataloader:\n",
    "                # Forward pass through the model to obtain predictions\n",
    "                outputs = self(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.tolist())\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-19 09:07:53,254]\u001b[0m A new study created in memory with name: no-name-a55bda56-4703-4be3-9919-a4a32df25c33\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with lr=1.730437906951078e-05 and epochs=43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-19 11:52:01,157]\u001b[0m Trial 0 finished with value: 0.2521853146853147 and parameters: {'lr': 1.730437906951078e-05, 'epochs': 43}. Best is trial 0 with value: 0.2521853146853147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with lr=4.319882669481712e-05 and epochs=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-19 12:48:06,469]\u001b[0m Trial 1 finished with value: 0.24694055944055945 and parameters: {'lr': 4.319882669481712e-05, 'epochs': 15}. Best is trial 0 with value: 0.2521853146853147.\u001b[0m\n",
      "\u001b[33m[W 2023-05-19 13:55:59,060]\u001b[0m Trial 2 failed with parameters: {'lr': 1.2628353623207541e-05, 'epochs': 38} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Juan Navarro\\AppData\\Local\\Temp\\ipykernel_7104\\3184732779.py\", line 18, in objective\n",
      "    model.train_cnn(train_dataset, train_labels)\n",
      "  File \"C:\\Users\\Juan Navarro\\AppData\\Local\\Temp\\ipykernel_7104\\682899009.py\", line 79, in train_cnn\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-05-19 13:55:59,086]\u001b[0m Trial 2 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m begin_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     27\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     29\u001b[0m finish_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     31\u001b[0m optuna_time \u001b[39m=\u001b[39m finish_time \u001b[39m-\u001b[39m begin_time\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     15\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m model \u001b[39m=\u001b[39m CNN(epochs\u001b[39m=\u001b[39mepochs, lr\u001b[39m=\u001b[39mlr, device\u001b[39m=\u001b[39mdevice, image_sizes\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m model\u001b[39m.\u001b[39;49mtrain_cnn(train_dataset, train_labels)   \n\u001b[0;32m     19\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_dataset)\n\u001b[0;32m     21\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(test_labels, predictions)\n",
      "Cell \u001b[1;32mIn[7], line 79\u001b[0m, in \u001b[0;36mCNN.train_cnn\u001b[1;34m(self, train_dataset, train_labels)\u001b[0m\n\u001b[0;32m     76\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(images)\n\u001b[0;32m     77\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 79\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     80\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     82\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Train the CNN with raw images --\n",
    "\n",
    "This cell uses the raw images (without any filter) to train the CNN\n",
    "model. First the best hyperparameters are found using optuna library\n",
    "and then the model with the best hyperparameters found is instantiated.\n",
    "\"\"\"\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # define hyperparameters to be optimized\n",
    "    lr = trial.suggest_float('lr', 0.00001, 0.001, log=True)\n",
    "    epochs = trial.suggest_int('epochs', 5, 50)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN(epochs=epochs, lr=lr, device=device, image_sizes=250).to(device)\n",
    "\n",
    "    model.train_cnn(train_dataset, train_labels)   \n",
    "    predictions = model.predict(test_dataset)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create optuna study and optimize the objetive function\n",
    "begin_time = time.time()\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "finish_time = time.time()\n",
    "\n",
    "optuna_time = finish_time - begin_time\n",
    "print(f\"Time taken to find best hyperparams -> {optuna_time} s\")\n",
    "# Print the best hyperparameters and the best objective value\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_value)\n",
    "\n",
    "\n",
    "# Instantiate the model with the best hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "begin_time = time.time()\n",
    "model = CNN(epochs=study.best_params['epochs'], lr=study.best_params['lr'], device=device, image_sizes=250).to(device)\n",
    "model.train_cnn(train_dataset, train_labels)\n",
    "finish_time = time.time()\n",
    "\n",
    "training_time = finish_time - begin_time\n",
    "print(f\"Time taken in training -> {training_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Test the CNN model with raw images --\n",
    "\n",
    "This cell traing the model previously trained with the test dataset.\n",
    "It gets the predictiosn and then compares the results using metrics\n",
    "like accuracy, precission, recall, f1 and roc/auc.\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(test_dataset)\n",
    "print(\"Model Preductions: \\n\", predictions)\n",
    "print(\"Real categories: \\n\", test_labels)\n",
    "\n",
    "# get the metrics\n",
    "print(confusion_matrix(test_labels, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(test_labels, predictions))\n",
    "print(\"Precision: \", precision_score(test_labels, predictions, average=None))\n",
    "print(\"Recall: \", recall_score(test_labels, predictions, average=None))\n",
    "print(\"F1 score: \", f1_score(test_labels, predictions, average=None))\n",
    "\n",
    "# for auc and roc there is an analysis for each category\n",
    "# get the accurate predictions matrix\n",
    "test_label_mat = []\n",
    "predictions_mat = []\n",
    "\n",
    "covid_true = []\n",
    "lung_op_true = []\n",
    "normal_true = []\n",
    "viral_pneu_true = []\n",
    "\n",
    "covid_pred = []\n",
    "lung_op_pred = []\n",
    "normal_pred = []\n",
    "viral_pneu_pred = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    \n",
    "    # y_test\n",
    "    covid_true.append(test_labels[i] == 0)\n",
    "    lung_op_true.append(test_labels[i] == 1)\n",
    "    normal_true.append(test_labels[i] == 2)\n",
    "    viral_pneu_true.append(test_labels[i] == 3)\n",
    "\n",
    "    # predictions\n",
    "    covid_pred.append(predictions[i] == 0)\n",
    "    lung_op_pred.append(predictions[i] == 1)\n",
    "    normal_pred.append(predictions[i] == 2)\n",
    "    viral_pneu_pred.append(predictions[i] == 3)\n",
    "\n",
    "test_label_mat.append(covid_true)\n",
    "test_label_mat.append(lung_op_true)\n",
    "test_label_mat.append(normal_true)\n",
    "test_label_mat.append(viral_pneu_true)\n",
    "\n",
    "predictions_mat.append(covid_pred)\n",
    "predictions_mat.append(lung_op_pred)\n",
    "predictions_mat.append(normal_pred)\n",
    "predictions_mat.append(viral_pneu_pred)\n",
    "\n",
    "# print the results and make the needed graphics\n",
    "auc = roc_auc_score(test_label_mat, predictions_mat, multi_class='ovo')\n",
    "print(\"General AUC:\", auc)\n",
    "\n",
    "categories = {'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral_Pneumonia': 3}\n",
    "\n",
    "for category, value in categories.items():\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_label_mat[value], predictions_mat[value])\n",
    "\n",
    "    auc = roc_auc_score(test_label_mat[value], predictions_mat[value])\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve {category} (AUC = %0.2f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line representing the random classifier\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {category}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de Mapas de Calor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
