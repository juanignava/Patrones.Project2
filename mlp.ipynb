{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-23 20:21:27.498666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 20:21:29.252267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import optuna\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset, random_split, ConcatDataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Normalize pixel values and create training and testing datasets --\n",
    "\n",
    "This cell normalizes the pixel values and creates a training\n",
    "and testing datasets considering the stratify technique.\n",
    "\"\"\"\n",
    "\n",
    "parent_folder_path = 'images/cropped_dataset/'\n",
    "categories = {'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral_Pneumonia': 3}\n",
    "arrays = []\n",
    "category_amount = []\n",
    "\n",
    "# get the category with the least images\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(parent_folder_path, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    category_amount.append(len(image_files))\n",
    "\n",
    "max_training = min(category_amount)\n",
    "\n",
    "# convert the images into a pytorch dataset\n",
    "for cat_folder, value in categories.items():\n",
    "\n",
    "    folder_path = os.path.join(parent_folder_path, cat_folder)\n",
    "    image_files = os.listdir(folder_path)\n",
    "\n",
    "    for i, file_name in enumerate(image_files):\n",
    "\n",
    "        if i >= max_training: break\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        image = Image.open(file_path)\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # verify all images are of the desired size\n",
    "        if image.size != (250, 250):\n",
    "            print(file_path, \" IS NOT 250x250, it is: \", image.size)\n",
    "            continue\n",
    "\n",
    "        if image_array.shape != (250, 250):\n",
    "            image_array = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "        arrays.append(image_array)\n",
    "\n",
    "# reshape the array\n",
    "arrays = np.array(arrays).astype(np.float32)\n",
    "arrays = arrays/ np.max(arrays)\n",
    "#image_data = np.stack(arrays, axis=0)\n",
    "#image_data = image_data.reshape(len(image_data), 1, 250, 250)\n",
    "\n",
    "arrays_labels = [0] * max_training\n",
    "arrays_labels += [1] * max_training\n",
    "arrays_labels += [2] * max_training\n",
    "arrays_labels += [3] * max_training\n",
    "\n",
    "arrays_labels = np.array(arrays_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arrays, arrays_labels, test_size=0.2, random_state=42, stratify=arrays_labels)\n",
    "\n",
    "print(\"Finished\")\n",
    "\n",
    "y_train = to_categorical(y_train.astype(int), num_classes=4)\n",
    "y_test = to_categorical(y_test.astype(int), num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 20:22:03.221572: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2285500000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "143/143 [==============================] - 8s 47ms/step - loss: 12.8577 - accuracy: 0.2635\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 7s 46ms/step - loss: 1.2397 - accuracy: 0.3916\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 7s 46ms/step - loss: 1.1580 - accuracy: 0.4161\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 7s 46ms/step - loss: 1.1753 - accuracy: 0.4078\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 7s 47ms/step - loss: 1.1791 - accuracy: 0.4094\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 7s 46ms/step - loss: 1.1406 - accuracy: 0.4240\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 7s 49ms/step - loss: 1.1475 - accuracy: 0.4173\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 7s 49ms/step - loss: 1.1288 - accuracy: 0.4286\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 7s 47ms/step - loss: 1.1435 - accuracy: 0.4182\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 7s 46ms/step - loss: 1.1428 - accuracy: 0.4111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03adb2bf10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo de red MLP personalizado\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Flatten(input_shape=(250, 250, 1)))\n",
    "\n",
    "# Capa oculta 1\n",
    "model_mlp.add(Dense(64, activation='relu'))\n",
    "model_mlp.add(Dropout(0.2))  # Se agrega Dropout para regularización\n",
    "\n",
    "# Capa oculta 2\n",
    "model_mlp.add(Dense(32, activation='relu'))\n",
    "model_mlp.add(Dropout(0.2))  # Se agrega Dropout para regularización\n",
    "\n",
    "# Capa de salida\n",
    "model_mlp.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model_mlp.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_mlp.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/72 [..............................] - ETA: 9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 20:23:13.115326: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 571500000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 12ms/step\n",
      "[[0.30952471 0.3097772  0.2868947  0.09380347]\n",
      " [0.30952471 0.3097772  0.2868947  0.09380347]\n",
      " [0.30952471 0.3097772  0.2868947  0.09380347]\n",
      " ...\n",
      " [0.3095247  0.30977717 0.28689468 0.09380345]\n",
      " [0.02987056 0.04122603 0.24392258 0.6849808 ]\n",
      " [0.3095247  0.30977717 0.28689468 0.09380345]]\n"
     ]
    }
   ],
   "source": [
    "pred = model_mlp.predict(X_test)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
